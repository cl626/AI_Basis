| Order | Q                                                            | A                                                            |
| ----- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1     | gauss过程的性质如何推导？                                    |                                                              |
| 2     | ~~plain\_bayes\_evaluation中P(Y=$c_k$)的极大似然估计怎么来的？~~ | 求导                                                         |
| 3     | 为什么正则化能avoid excessive-fitting？                      | 通过加入关于高指数项系数的惩罚项，目标函数极小化时，较高指数项x的系数必然较小，因此得到泛化 |
| 4     | Adboost更多的是一种方法？<br />提升树的理解？                | 1.  想法是有效利用得到的分类器<br />2. constantly elevate拟合的好的model&预测错误率高的样本' weight，<br />一种朴素的建模方法<br />3. 提升树→目标与fm-1相减得到新的目标函数，minimize Loss |
| 5     | Adboost二分类加法器的理解                                    | 1. 前向分步算法——分步取得βmb(x;ym)的系数<br />2. 试推导      |
| 6     | 需要推导各算法的误差界                                       |                                                              |
| 7     | logistic，最大熵与SVM的联系与区别                            | 1. classifier,预设输出形式，lagrange求极小点<br />2. 什么是最大熵方法 |
| 8     | 1. 最大熵方法的建模方式<br />求解中x,y的特征函数f(x,y)给定吗？如何理解？<br />最大熵方法是决策树中的最大熵吗？ | 1. 熵形式+lagrange极小化<br />2.                             |
| 9     | 机器学习有哪些推导方式？                                     | 1. 最优化<br />2. 代数变形<br />3. 概统公式                  |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |
|       |                                                              |                                                              |

